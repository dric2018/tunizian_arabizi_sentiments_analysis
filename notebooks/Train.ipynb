{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "visible-tension",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center'>\n",
    "    Experiment begins here\n",
    "</div>\n",
    "\n",
    "# Notebook structure\n",
    "1. [Packages used](#Import-packages)\n",
    "2. [Some utilities](#Some-utilities)\n",
    "3. [Dataset management](#Dataset)\n",
    "4. [Modeling](#Modeling)\n",
    "5. [Training pipeline](#Training-pipeline)\n",
    "6. [Prediction time](#Prediction-time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-twins",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "super-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spanish-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataSet, DataModule\n",
    "from model import Model, Model1, TransformerModel\n",
    "from utils import ramp_scheduler\n",
    "from config import Config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch as th\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, GPUStatsMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-elizabeth",
   "metadata": {},
   "source": [
    "## Some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coated-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n"
     ]
    }
   ],
   "source": [
    "_ = seed_everything(Config.seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-strap",
   "metadata": {},
   "source": [
    "epochs = [x for x in range(100)]\n",
    "lrs = [ramp_scheduler(epoch = x) for x in epochs]\n",
    "\n",
    "plt.title('LR Scheduler function')\n",
    "plt.plot(epochs, lrs)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('learning rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-referral",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Dataset\">\n",
    "   Dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "together-memphis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13P0QT0</td>\n",
       "      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKCLXCJ</td>\n",
       "      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1TVXIJ</td>\n",
       "      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0TTYY8</td>\n",
       "      <td>ak slouma</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68DX797</td>\n",
       "      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  label  fold\n",
       "0  13P0QT0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...     -1     7\n",
       "1  SKCLXCJ       cha3eb fey9elkoum menghir ta7ayoul ou kressi     -1     9\n",
       "2  V1TVXIJ  bereau degage nathef ya slim walahi ya7chiw fi...     -1     7\n",
       "3  U0TTYY8                                          ak slouma      1     6\n",
       "4  68DX797  entom titmanou lina a7na 3iid moubarik a7na ch...     -1     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(Config.data_dir, 'Train_10_folds.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "checked-monte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training on 52500 samples belonging to 3 classes\n",
      "[INFO] Validating on 17500 samples belonging to 3 classes\n",
      "CPU times: user 364 ms, sys: 36 ms, total: 400 ms\n",
      "Wall time: 7.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dm = DataModule(\n",
    "    df=train_df,\n",
    "    frac=1,\n",
    "    train_batch_size= Config.train_batch_size,\n",
    "    test_batch_size= Config.test_batch_size,\n",
    "    test_size = .25\n",
    ")\n",
    "\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-riding",
   "metadata": {},
   "source": [
    "## Model part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-opening",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Modeling\">\n",
    "   Modeling\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-marker",
   "metadata": {},
   "source": [
    "### 1- Class weights computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "national-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 ms, sys: 136 Âµs, total: 13.1 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.7965, 0.6102, 9.4620])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# compute class weights\n",
    "class_w = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=train_df.label.unique(), \n",
    "    y=train_df.label.values\n",
    ")\n",
    "class_w = th.from_numpy(class_w).float()\n",
    "class_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-treaty",
   "metadata": {},
   "source": [
    "### 2- Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crude-chess",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1(\n",
      "  (embedding): Embedding(119548, 100)\n",
      "  (encoder): GRU(100, 350, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (classifier): Linear(in_features=700, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "CPU times: user 383 ms, sys: 12.1 ms, total: 395 ms\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.base_model)\n",
    "\n",
    "# define model\n",
    "model = Model1(\n",
    "    class_w=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-reply",
   "metadata": {},
   "source": [
    "## Training config/setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-blade",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Training-pipeline\">\n",
    "   Training pipeline\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-stretch",
   "metadata": {},
   "source": [
    "### 1- Calbacks definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ready-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = ModelCheckpoint(\n",
    "    filename=os.path.join(\n",
    "        Config.models_dir, f\"arabizi-sentiments-{Config.base_model}\"),\n",
    "    monitor='val_acc',\n",
    "    mode=\"max\"\n",
    ")\n",
    "es = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=Config.early_stopping_patience,\n",
    "    mode=\"max\"\n",
    ")\n",
    "gpu_stats = GPUStatsMonitor(\n",
    "    memory_utilization=True,\n",
    "    gpu_utilization=True,\n",
    "    intra_step_time=False,\n",
    "    inter_step_time=False,\n",
    "    fan_speed=True,\n",
    "    temperature=True,\n",
    ")\n",
    "\n",
    "callbacks_list = [es, model_ckpt, gpu_stats]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-victorian",
   "metadata": {},
   "source": [
    "### 2- Logger definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rubber-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = sorted([folder for folder in os.listdir(os.path.join(Config.logs_dir, 'zindi-arabizi')) if len(folder.split('.'))<=1])\n",
    "\n",
    "if len(walk) > 0:\n",
    "    version = int(walk[-1].split('_')[-1]) +1\n",
    "else:\n",
    "    version = 0\n",
    "    \n",
    "tb_logger = TensorBoardLogger(\n",
    "    save_dir=Config.logs_dir,\n",
    "    name='zindi-arabizi',\n",
    "    default_hp_metric=False\n",
    ")\n",
    "# save experiment config\n",
    "\n",
    "with open(os.path.join(Config.logs_dir, 'zindi-arabizi',f'conf-exp-{version}.txt'), 'w') as conf:\n",
    "    conf.write(f'================== Config file version {version} ===================\\n\\n')\n",
    "    d = dict(Config.__dict__)\n",
    "    conf_dict = {k:d[k] for k in d.keys() if '__' not in k}\n",
    "    \n",
    "    for k in conf_dict:\n",
    "        v = conf_dict[k]\n",
    "        conf.write(f'{k} : {v}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-graduate",
   "metadata": {},
   "source": [
    "### 3- Trainer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rural-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=tb_logger, \n",
    "    checkpoint_callback=True, \n",
    "    gpus=1,\n",
    "    # fast_dev_run=True,\n",
    "    min_epochs=2,\n",
    "    max_epochs=Config.num_epochs,\n",
    "    precision=32,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-contamination",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Training-job\">\n",
    "   Training job\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amber-latitude",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | embedding  | Embedding | 12.0 M\n",
      "1 | encoder    | GRU       | 7.6 M \n",
      "2 | classifier | Linear    | 2.1 K \n",
      "3 | dropout    | Dropout   | 0     \n",
      "-----------------------------------------\n",
      "19.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 M    Total params\n",
      "78.135    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b73deb229f48a7b4c70a6fae823e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n",
      "Process Process-16:\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f83600cd310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Process Process-15:\n",
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/zeusdric/miniconda3/envs/deepl/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=model, \n",
    "    datamodule=dm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-airplane",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Prediction-time\">\n",
    "   Prediction time\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    th.jit.save(\n",
    "        model.to_torchscript(),\n",
    "        os.path.join(\n",
    "            Config.models_dir, \n",
    "            f'arabizi-sentiments-{Config.base_model}-version-{version}.bin'\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"[ERROR]\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-programming",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0467e1f93b2d439aa16fabedba942fd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "19aa263dc6e8407d9443a52a671b169f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1b17d09276644923a08d8135e32e8b6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_2a633650e4684c01b761f9b696feeb5d",
       "max": 2,
       "style": "IPY_MODEL_4a81e38797404a8fabb8aa34a33e8872",
       "value": 2
      }
     },
     "2a633650e4684c01b761f9b696feeb5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "2ad4be2a01fb4cbdbcb17b1f677e3f4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3f24c611461b4e2e9c4b6a5c0387d25f",
       "style": "IPY_MODEL_73b0995319614e7e9e1d78e4f5bb987a",
       "value": "Epoch 1:   8%"
      }
     },
     "2af50529153c42819f10f543a6a7960b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_839df26a7d01443390707f2d2bd89968",
       "style": "IPY_MODEL_3ab9bfa5d786459d895094fe0f99ecb0",
       "value": " 69/69 [00:14&lt;00:00,  5.64it/s]"
      }
     },
     "2bac397c5fc44b9494ad92d8f6dcaebf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_e1cd5486c6d542c6937488f99ab5547e",
       "max": 275,
       "style": "IPY_MODEL_e81b2edaf6a84f808f7124a20ad8d616",
       "value": 23
      }
     },
     "35ae8dbf83784de3a49a970d562cd93f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "3ab9bfa5d786459d895094fe0f99ecb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3f24c611461b4e2e9c4b6a5c0387d25f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40314daa74ad4849b7e03c80643d61b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_f022fd536f7f46c1ad9ca782307d0a40",
       "max": 69,
       "style": "IPY_MODEL_19aa263dc6e8407d9443a52a671b169f",
       "value": 69
      }
     },
     "423e7f73c6304ce38aad91a8c7d46977": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "49af1fb0b9f74aa2aa12ecddd4e16ea6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4a81e38797404a8fabb8aa34a33e8872": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "52096ec74fd342f095a50767b3161fcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_423e7f73c6304ce38aad91a8c7d46977",
       "style": "IPY_MODEL_49af1fb0b9f74aa2aa12ecddd4e16ea6",
       "value": "Validation sanity check: 100%"
      }
     },
     "629eb8283fa04ff28fb9b834ff0aaa5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "73b0995319614e7e9e1d78e4f5bb987a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "839df26a7d01443390707f2d2bd89968": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "89894f09f0f94506a3e57f8371ec05a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8d7f19c1de004cb8ab21a6c46a0be11c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ee68f81932e940adaaea2716579b71c4",
       "style": "IPY_MODEL_a71b4b4ae20c4212a4fe5709beadc474",
       "value": " 2/2 [00:00&lt;00:00,  3.17it/s]"
      }
     },
     "8e4b5e29c60a4b1cbaf819748f982ce1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "95b73deb229f48a7b4c70a6fae823e19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2ad4be2a01fb4cbdbcb17b1f677e3f4c",
        "IPY_MODEL_2bac397c5fc44b9494ad92d8f6dcaebf",
        "IPY_MODEL_a3a83ceb21654ff2bc1322e5608901c6"
       ],
       "layout": "IPY_MODEL_629eb8283fa04ff28fb9b834ff0aaa5f"
      }
     },
     "a3a83ceb21654ff2bc1322e5608901c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b90a14522e1045baa79381eb08c0c104",
       "style": "IPY_MODEL_89894f09f0f94506a3e57f8371ec05a8",
       "value": " 23/275 [00:17&lt;03:13,  1.30it/s, loss=0.844, v_num=4, val_loss=0.853, val_acc=0.545, train_acc_step=0.605, train_acc_epoch=0.546]"
      }
     },
     "a71b4b4ae20c4212a4fe5709beadc474": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b90a14522e1045baa79381eb08c0c104": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1cd5486c6d542c6937488f99ab5547e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "e81b2edaf6a84f808f7124a20ad8d616": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ecce14ca0b63450e9564df2e9676e497": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f52e3c4ae3ad4582877bf611293de582",
       "style": "IPY_MODEL_8e4b5e29c60a4b1cbaf819748f982ce1",
       "value": "Validating: 100%"
      }
     },
     "ee68f81932e940adaaea2716579b71c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f022fd536f7f46c1ad9ca782307d0a40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f52e3c4ae3ad4582877bf611293de582": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
