{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "perfect-narrative",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center'>\n",
    "    Experiment begins here\n",
    "</div>\n",
    "\n",
    "# Notebook structure\n",
    "1. [Packages used](#Import-packages)\n",
    "2. [Some utilities](#Some-utilities)\n",
    "3. [Dataset management](#Dataset)\n",
    "4. [Modeling](#Modeling)\n",
    "5. [Training pipeline](#Training-pipeline)\n",
    "6. [Prediction time](#Prediction-time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-maintenance",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charged-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hourly-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataSet, DataModule\n",
    "from model import Model\n",
    "from utils import ramp_scheduler\n",
    "from config import Config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch as th\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, GPUStatsMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-biography",
   "metadata": {},
   "source": [
    "## Some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "soviet-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n"
     ]
    }
   ],
   "source": [
    "_ = seed_everything(Config.seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continuing-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [x for x in range(100)]\n",
    "lrs = [ramp_scheduler(epoch = x) for x in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signed-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('LR Scheduler function')\n",
    "plt.plot(epochs, lrs)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('learning rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-dancing",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Dataset\">\n",
    "   Dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "figured-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13P0QT0</td>\n",
       "      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKCLXCJ</td>\n",
       "      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1TVXIJ</td>\n",
       "      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0TTYY8</td>\n",
       "      <td>ak slouma</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68DX797</td>\n",
       "      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  label  fold\n",
       "0  13P0QT0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...     -1     7\n",
       "1  SKCLXCJ       cha3eb fey9elkoum menghir ta7ayoul ou kressi     -1     9\n",
       "2  V1TVXIJ  bereau degage nathef ya slim walahi ya7chiw fi...     -1     7\n",
       "3  U0TTYY8                                          ak slouma      1     6\n",
       "4  68DX797  entom titmanou lina a7na 3iid moubarik a7na ch...     -1     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(Config.data_dir, 'Train_10_folds.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "charged-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training on 59500 samples belonging to 3 classes\n",
      "[INFO] Validating on 10500 samples belonging to 3 classes\n",
      "CPU times: user 410 ms, sys: 23.7 ms, total: 434 ms\n",
      "Wall time: 6.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dm = DataModule(\n",
    "    df=train_df,\n",
    "    frac=1,\n",
    "    train_batch_size= Config.train_batch_size,\n",
    "    test_batch_size= Config.test_batch_size,\n",
    "    test_size = .15\n",
    ")\n",
    "\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-spectacular",
   "metadata": {},
   "source": [
    "## Model part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-looking",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Modeling\">\n",
    "   Modeling\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-cathedral",
   "metadata": {},
   "source": [
    "### 1- Class weights computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "improving-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 ms, sys: 107 Âµs, total: 12.9 ms\n",
      "Wall time: 12.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.7965, 0.6102, 9.4620])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# compute class weights\n",
    "class_w = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=train_df.label.unique(), \n",
    "    y=train_df.label.values\n",
    ")\n",
    "class_w = th.from_numpy(class_w).float()\n",
    "class_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-invalid",
   "metadata": {},
   "source": [
    "### 2- Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "front-criminal",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "CPU times: user 2.85 s, sys: 342 ms, total: 3.19 s\n",
      "Wall time: 4.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# define model\n",
    "model = Model(\n",
    "    class_w=class_w\n",
    ")\n",
    "\n",
    "print(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sophisticated-spouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-fishing",
   "metadata": {},
   "source": [
    "## Training config/setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-stuff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Training-pipeline\">\n",
    "   Training pipeline\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-promotion",
   "metadata": {},
   "source": [
    "### 1- Calbacks definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "diagnostic-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = ModelCheckpoint(\n",
    "    filename=os.path.join(\n",
    "        Config.models_dir, f\"arabizi-sentiments-{Config.base_model}\"),\n",
    "    monitor='val_acc',\n",
    "    mode=\"max\"\n",
    ")\n",
    "es = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=10,\n",
    "    mode=\"max\"\n",
    ")\n",
    "gpu_stats = GPUStatsMonitor(\n",
    "    memory_utilization=True,\n",
    "    gpu_utilization=True,\n",
    "    intra_step_time=False,\n",
    "    inter_step_time=False,\n",
    "    fan_speed=True,\n",
    "    temperature=True,\n",
    ")\n",
    "\n",
    "callbacks_list = [es, model_ckpt, gpu_stats]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-deviation",
   "metadata": {},
   "source": [
    "### 2- Logger definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "driving-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = TensorBoardLogger(\n",
    "    save_dir=Config.logs_dir,\n",
    "    name='zindi-arabizi',\n",
    "    default_hp_metric=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-trust",
   "metadata": {},
   "source": [
    "### 3- Trainer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accompanied-benjamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=tb_logger, \n",
    "    checkpoint_callback=True, \n",
    "    gpus=1,\n",
    "    fast_dev_run=True,\n",
    "    min_epochs=2,\n",
    "    max_epochs=Config.num_epochs,\n",
    "    precision=32,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-blast",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Training-job\">\n",
    "   Training job\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "plastic-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type            | Params\n",
      "--------------------------------------------\n",
      "0 | encoder | DistilBertModel | 134 M \n",
      "1 | dropout | Dropout         | 0     \n",
      "2 | pooler  | Linear          | 590 K \n",
      "3 | decoder | Linear          | 2.3 K \n",
      "--------------------------------------------\n",
      "135 M     Trainable params\n",
      "0         Non-trainable params\n",
      "135 M     Total params\n",
      "541.308   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-09.\n",
      "Adjusting learning rate of group 1 to 3.0000e-09.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa246622fef64a8287979752d3da94fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The `preds` should be probabilities, but values were detected outside of [0,1] range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-eee476b51974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         model_ref.optimizer_step(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;31m# wraps into LightingOptimizer only for running step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightningOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_lightning_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mrun_optimizer_step\u001b[0;34m(self, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[1;32m    645\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                             )\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dric/Zindi/COMPETITIONS/NLP/AI4D_Tunisian_arabizi/scripts/model.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# logging stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dric/Zindi/COMPETITIONS/NLP/AI4D_Tunisian_arabizi/scripts/model.py\u001b[0m in \u001b[0;36mget_acc\u001b[0;34m(self, preds, targets)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/metrics/functional/accuracy.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(preds, target, threshold, top_k, subset_accuracy)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_accuracy_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_accuracy_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/metrics/functional/accuracy.py\u001b[0m in \u001b[0;36m_accuracy_update\u001b[0;34m(preds, target, threshold, top_k, subset_accuracy)\u001b[0m\n\u001b[1;32m     23\u001b[0m ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_format_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTILABEL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m_input_format_classification\u001b[0;34m(preds, target, threshold, top_k, num_classes, is_multiclass)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     case = _check_classification_inputs(\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, is_multiclass, top_k)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# Baisc validation (that does not need case/type information)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0m_basic_input_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multiclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# Check that shape/types fall into one of the cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepl/lib/python3.8/site-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, is_multiclass)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `preds` should be probabilities, but values were detected outside of [0,1] range.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `preds` should be probabilities, but values were detected outside of [0,1] range."
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=model, \n",
    "    datamodule=dm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-demonstration",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='text-align:center' id=\"Prediction-time\">\n",
    "   Prediction time\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-correlation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "023c8a29f13249b88e6bfc71c01d9c36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "570c740b157341e39823a7c38ed755d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7fd058ac1e324b7493727f53a9583a3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "803268b36c9a4c2f91bea7259da9982a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9661967e5d414ff1b2296523b30ccf8e",
       "style": "IPY_MODEL_023c8a29f13249b88e6bfc71c01d9c36",
       "value": " 0/2 [00:00&lt;?, ?it/s]"
      }
     },
     "8f4ae0d895ea4624a3ba9d73e5904072": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "9661967e5d414ff1b2296523b30ccf8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a4068f5ac28f4820b6bae1e27de4e587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_ca4ddc2948584c4b94e9160e7812a1e4",
       "max": 2,
       "style": "IPY_MODEL_b38d1cbc417d4eb4b1047b4c8cb46303"
      }
     },
     "b38d1cbc417d4eb4b1047b4c8cb46303": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ca4ddc2948584c4b94e9160e7812a1e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "cdeb7e2a4af04f9d9a8ec61ca8e7268e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7fd058ac1e324b7493727f53a9583a3c",
       "style": "IPY_MODEL_570c740b157341e39823a7c38ed755d9",
       "value": "Epoch 0:   0%"
      }
     },
     "fa246622fef64a8287979752d3da94fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cdeb7e2a4af04f9d9a8ec61ca8e7268e",
        "IPY_MODEL_a4068f5ac28f4820b6bae1e27de4e587",
        "IPY_MODEL_803268b36c9a4c2f91bea7259da9982a"
       ],
       "layout": "IPY_MODEL_8f4ae0d895ea4624a3ba9d73e5904072"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
